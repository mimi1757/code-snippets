{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WidsModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_0em_eHHvmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "dd3f252b-7c2b-4263-9de9-1c4c531b6d8e"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import  pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "# load data\n",
        "\n",
        "#import os\n",
        "#for dirname, _, filenames in os.walk('../input'):\n",
        "#    for filename in filenames:\n",
        "#        print(os.path.join(dirname, filename))\n",
        "pd.set_option('max_columns', None) \n",
        "df_train=pd.read_csv(\"./drive/MyDrive/TrainingWiDS2021.csv\")\n",
        "df_test=pd.read_csv(\"./drive/MyDrive/UnlabeledWiDS2021.csv\")\n",
        "\n",
        "cats = []\n",
        "for c in list(df_train.columns):\n",
        "  unique = df_train[c].nunique()\n",
        "  if unique <= 5:\n",
        "      # decide this is a category\n",
        "      newcol, code = pd.factorize(df_train[c], na_sentinel=None)\n",
        "      cats.append(code)\n",
        "      df_train[c] = newcol\n",
        "cols = df_train.select_dtypes([np.number]).columns          ## string features with more than 5 categories are thrown out\n",
        "X = df_train[cols] \n",
        "\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\"\"\"dropped_na = []                                        #only numeric data is kept - skipping admission ward data - some binary columns \n",
        "for c in list(X.columns):\n",
        "  if X[c].isna().mean()>.5:\n",
        "    X.drop(c, axis = 1, inplace=True)\n",
        "    dropped_na.append(c)\"\"\"\n",
        "\n",
        "\n",
        "                                      #replace nan with mean of column - binary columns now trinary\n",
        "X.drop(['encounter_id', 'hospital_id', 'icu_id'], axis = 1, inplace = True) #id has no affect on diabetes\n",
        "                                 \n",
        "def correlation(dataset, threshold):                        #function calculates the corplot, gathers columns that are correlated into corr_features\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: \n",
        "                colname = corr_matrix.columns[i]        \n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "corr_features = correlation(X, 0.7)\n",
        "X.drop(corr_features,axis=1, inplace=True)                   #remove correlated columns\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-84c418c52ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#        print(os.path.join(dirname, filename))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/MyDrive/TrainingWiDS2021.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/MyDrive/UnlabeledWiDS2021.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/TrainingWiDS2021.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WrLC_jGTcQA"
      },
      "source": [
        "# New Section\n",
        "reads in data from local drive, cleans up a bit\n",
        "\n",
        "removes correlated data\n",
        "replaces nan with mean of column\n",
        "string factors with more than 5 levels are thrown out\n",
        "\n",
        "next section keeps only columns determined to be useful according to Karen's analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VylxoglncR0F",
        "outputId": "340cfd19-8640-41e8-8732-b926b42b4973"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'age', 'bmi', 'elective_surgery', 'gender', 'height',\n",
              "       'icu_admit_source', 'icu_stay_type', 'pre_icu_los_days',\n",
              "       'readmission_status', 'albumin_apache', 'apache_2_diagnosis',\n",
              "       'arf_apache', 'bilirubin_apache', 'bun_apache', 'creatinine_apache',\n",
              "       'fio2_apache', 'gcs_eyes_apache', 'gcs_motor_apache',\n",
              "       'gcs_unable_apache', 'gcs_verbal_apache', 'glucose_apache',\n",
              "       'heart_rate_apache', 'hematocrit_apache', 'intubated_apache',\n",
              "       'map_apache', 'paco2_apache', 'pao2_apache', 'ph_apache',\n",
              "       'resprate_apache', 'sodium_apache', 'temp_apache', 'urineoutput_apache',\n",
              "       'ventilated_apache', 'wbc_apache', 'd1_diasbp_invasive_max',\n",
              "       'd1_diasbp_invasive_min', 'd1_diasbp_max', 'd1_diasbp_min',\n",
              "       'd1_heartrate_min', 'd1_mbp_invasive_max', 'd1_resprate_max',\n",
              "       'd1_resprate_min', 'd1_spo2_max', 'd1_spo2_min',\n",
              "       'd1_sysbp_invasive_max', 'd1_sysbp_invasive_min', 'd1_temp_max',\n",
              "       'h1_diasbp_invasive_max', 'h1_diasbp_invasive_min', 'h1_diasbp_max',\n",
              "       'h1_diasbp_min', 'h1_mbp_invasive_max', 'h1_resprate_max',\n",
              "       'h1_resprate_min', 'h1_spo2_max', 'h1_spo2_min',\n",
              "       'h1_sysbp_invasive_max', 'h1_temp_max', 'd1_calcium_max',\n",
              "       'd1_glucose_min', 'd1_hco3_max', 'd1_inr_max', 'd1_lactate_max',\n",
              "       'd1_platelets_max', 'd1_potassium_max', 'd1_potassium_min',\n",
              "       'h1_albumin_max', 'h1_bilirubin_max', 'h1_bun_max', 'h1_calcium_max',\n",
              "       'h1_glucose_max', 'h1_hco3_max', 'h1_hemaglobin_max', 'h1_lactate_max',\n",
              "       'h1_platelets_max', 'h1_potassium_max', 'h1_sodium_max', 'h1_wbc_max',\n",
              "       'd1_arterial_pco2_max', 'd1_arterial_ph_max', 'd1_arterial_ph_min',\n",
              "       'd1_arterial_po2_max', 'd1_arterial_po2_min', 'd1_pao2fio2ratio_max',\n",
              "       'h1_arterial_pco2_max', 'h1_arterial_ph_max', 'h1_arterial_po2_max',\n",
              "       'h1_pao2fio2ratio_max', 'aids', 'cirrhosis', 'hepatic_failure',\n",
              "       'immunosuppression', 'leukemia', 'lymphoma',\n",
              "       'solid_tumor_with_metastasis', 'diabetes_mellitus'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usm_wa3ZI0da"
      },
      "source": [
        "X_f=X.drop(labels=['diabetes_mellitus'],axis=1)         #X full\n",
        "y_f=X['diabetes_mellitus']                              #y full\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_f, y_f, test_size=0.30, random_state=1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_validation = sc.transform(X_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75EEMCAUc52K",
        "outputId": "39cee870-2a8f-4f55-d182-97af26114345"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on validation dataset\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.806340913747183\n",
            "[[ 2298  6134]\n",
            " [ 1428 29188]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.27      0.38      8432\n",
            "           1       0.83      0.95      0.89     30616\n",
            "\n",
            "    accuracy                           0.81     39048\n",
            "   macro avg       0.72      0.61      0.63     39048\n",
            "weighted avg       0.78      0.81      0.78     39048\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2gZu2XKcM4o",
        "outputId": "047e2d43-29dc-4f0d-eafd-84b6e986f0b8"
      },
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "model = QuadraticDiscriminantAnalysis()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))\n",
        "# QDA underperforms LDA because of the high # of predictor# keep only gaussian distr. data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.744698832206515\n",
            "[[ 3655  4777]\n",
            " [ 5192 25424]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.43      0.42      8432\n",
            "           1       0.84      0.83      0.84     30616\n",
            "\n",
            "    accuracy                           0.74     39048\n",
            "   macro avg       0.63      0.63      0.63     39048\n",
            "weighted avg       0.75      0.74      0.75     39048\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNf7ov7pdSF-",
        "outputId": "8ce9a34f-98e0-4e41-e4d5-b49c12a8a7fd"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8055726285597213\n",
            "[[ 2087  6345]\n",
            " [ 1247 29369]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.25      0.35      8432\n",
            "           1       0.82      0.96      0.89     30616\n",
            "\n",
            "    accuracy                           0.81     39048\n",
            "   macro avg       0.72      0.60      0.62     39048\n",
            "weighted avg       0.78      0.81      0.77     39048\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKsHYbYIdWk1",
        "outputId": "02f564c1-f06b-4941-feaa-f1a59c55736e"
      },
      "source": [
        "from sklearn import svm\n",
        "model = svm.SVC()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8147152222905142\n",
            "[[ 2167  6265]\n",
            " [  970 29646]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.26      0.37      8432\n",
            "           1       0.83      0.97      0.89     30616\n",
            "\n",
            "    accuracy                           0.81     39048\n",
            "   macro avg       0.76      0.61      0.63     39048\n",
            "weighted avg       0.80      0.81      0.78     39048\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Vazr7AfeIu"
      },
      "source": [
        "By consensus of the group, LDA was chosen as the model of choice. Although Logistic Regression and SVC also did well, SVC took more time and Logistic Regression theory is dependent on Gaussian distributed data (which we do not have)"
      ]
    }
  ]
}